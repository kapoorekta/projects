{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at finetuning ChatGPT on a YT creator's video title and video transcripts to generate more personalized video transcript outlines given a video title. The notebook compares the finetuned model output to that of a base gpt-3.5-turbo for the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset taken from https://www.kaggle.com/code/thedevastator/mrbeast-transcripts-starter-notebook/input\n",
    "data_df = pd.read_csv(\"kaggle_yt_video_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking most recent 50 videos\n",
    "data_subset = data_df.sort_values(by=\"publish_date\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_list = data_subset[0:50][\"transcript\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.  Summarize transcripts: \n",
    " The transcripts fed directly into the finetuning model would exceed the token limit. As a solution, we first summarize the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []\n",
    "for transcript in transcript_list:\n",
    "    summary_prompt = (\n",
    "        f\"Summarize the following transcript of a Youtube video: {transcript}.\"\n",
    "    )\n",
    "    gpt_summary = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.7,\n",
    "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "    )\n",
    "    result = gpt_summary.choices[0].message.content.strip('\"\"')\n",
    "    summary_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset[\"summary\"] = summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = data_subset[\"title\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Finetune the model on the title and the transcript summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "data = []\n",
    "for val in range(len(titles_list)):\n",
    "    prompt = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful chatbot that writes youtube video transcript outlines given a video title.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Given the following video title for a Youtube video: {titles_list[val]}, what would be a good video outline? \",\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": f\"{summary_list[val]}\"},\n",
    "        ]\n",
    "    }\n",
    "    data.append(prompt)\n",
    "# Open the JSONL file in write mode\n",
    "with jsonlines.open(\"output.jsonl\", mode=\"w\") as writer:\n",
    "    # Iterate over the list of dictionaries\n",
    "    for item in data:\n",
    "        # Write each dictionary as a separate line in the JSONL file\n",
    "        writer.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a helpful chatbot that writes youtube video transcript outlines given a video title.'}\n",
      "{'role': 'user', 'content': 'Given the following video title for a Youtube video: Hydraulic Press Vs Lamborghini, what would be a good video outline? '}\n",
      "{'role': 'assistant', 'content': 'The video features a series of extreme experiments, including flattening a Lamborghini with a hydraulic press, dropping a car from a helicopter into a pool of Orbeez, and testing if semi-trucks can stop a train. The experiments are over-the-top and often result in destruction, but also include humor and excitement from the participants. The video ends with a dramatic explosion of the flattened Lamborghini.'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"output.jsonl\"\n",
    "# Load the dataset\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Sample training data format\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(\n",
    "            k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\")\n",
    "            for k in message\n",
    "        ):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "\n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "# Estimate the number of tokens\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 121, 208\n",
      "mean / median: 159.48, 158.0\n",
      "p5 / p95: 135.8, 188.2\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 63, 147\n",
      "mean / median: 97.42, 96.5\n",
      "p5 / p95: 74.7, 125.2\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(\n",
    "    f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~7974 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~23922 tokens\n"
     ]
    }
   ],
   "source": [
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 50\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(\n",
    "    min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens\n",
    ")\n",
    "print(\n",
    "    f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\"\n",
    ")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(\n",
    "    f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-7TY1KQRzwaf1HevG86djSLYF', bytes=40404, created_at=1716700619, filename='output.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(file=open(\"output.jsonl\", \"rb\"), purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-rAGnT9XdLyId6FCjvrJAtPby', created_at=1716700664, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-IzVYmXYvxXSW8yrBJM3dP4nZ', result_files=[], seed=446844219, status='validating_files', trained_tokens=None, training_file='file-7TY1KQRzwaf1HevG86djSLYF', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fine-tuning job\n",
    "client.fine_tuning.jobs.create(\n",
    "    training_file=\"file-7TY1KQRzwaf1HevG86djSLYF\", model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-rAGnT9XdLyId6FCjvrJAtPby', created_at=1716700664, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:ben::9T0gvsHl', finished_at=1716701196, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-IzVYmXYvxXSW8yrBJM3dP4nZ', result_files=['file-YzJiigp5bZD8IRYNuyPE7LhA'], seed=446844219, status='succeeded', trained_tokens=23622, training_file='file-7TY1KQRzwaf1HevG86djSLYF', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-OPDXiPEtvGIUXoOBtEAGzfVr', created_at=1714085198, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:ben::9I2M7Zs3', finished_at=1714085985, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-IzVYmXYvxXSW8yrBJM3dP4nZ', result_files=['file-HVeLIombdpUcEBxXPTQEtr1C'], seed=1915870371, status='succeeded', trained_tokens=92526, training_file='file-V9JKTzhSsLOMDDIS2OAwVEC9', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-OTsR6uI9YiIGteDT6ozY22vd', created_at=1714084640, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:ben::9I2D54eN', finished_at=1714085425, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-IzVYmXYvxXSW8yrBJM3dP4nZ', result_files=['file-luJJi6b6GpzuN2HGb1uOIlon'], seed=1822913095, status='succeeded', trained_tokens=92526, training_file='file-AHYtMuariUEtHhCX2FLAgXwl', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)], object='list', has_more=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test the finetuned model and a standard gpt 3.5 turbo on the same prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transcript = data_df[data_df[\"title\"] == \"I Built A Giant House Using Only Legos\"][\n",
    "    \"transcript\"\n",
    "].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video shows the process of building a giant Lego house using over a million Legos, including building furniture like a toilet, TV, bed, and desk. The house is tested for durability against elements like hurricanes, earthquakes, and even a 50-caliber gun. The house is also tested for security and egg-proofing. Eventually, the house is destroyed by a Lego car, but it is announced that one lucky Instagram follower will get the house. The video ends with the realization that the house was built just to be torn down for content.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a summary for a test transcript\n",
    "summary_prompt = (\n",
    "    f\"Summarize the following transcript of a Youtube video: {test_transcript}.\"\n",
    ")\n",
    "gpt_summary = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    ")\n",
    "result = gpt_summary.choices[0].message.content.strip('\"\"')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Mr. Beast has teamed up with a bunch of friends to build a giant Lego house in stop-motion style. They rent a warehouse and start building walls, floors, and rooms using thousands of Lego bricks. Various challenges and funny moments occur as they build and move through the Lego house. Eventually, they complete the house with a working toilet and a blimp hovering above it. The video ends with an exciting announcement that the Lego house itself will be given away to a random viewer who comments on the video.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Testing the fine-tuned model\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0125:ben::9T0gvsHl\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful chatbot that writes youtube video transcripts given a video title.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Mr.Beast is planning to make YT video with the following title: 'I Built A Giant House Using Only Legos'. what would be a good video outline?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Title: I Built A Giant House Using Only Legos\\n\\nOutline:\\n0:00 - 0:30 Introduction\\n- Brief introduction of Mr. Beast and the challenge of building a giant house using only Legos\\n- Excitement and anticipation for the upcoming project\\n\\n0:30 - 1:00 Gathering Supplies\\n- Showing the process of gathering a massive amount of Legos needed for the project\\n- Setting up the workspace for the construction of the Lego house\\n\\n1:00 - 3:00 Building the Foundation\\n- Time-lapse footage of laying down the foundation for the Lego house\\n- Overcoming challenges and setbacks during the construction process\\n\\n3:00 - 5:00 Constructing the Walls and Roof\\n- Focusing on building the walls and roof of the giant Lego house\\n- Detailing the intricate design elements and creative solutions used in construction\\n\\n5:00 - 6:00 Final Touches and Decorations\\n- Adding final touches, details, and decorations to the Lego house\\n- Showcasing the completed giant Lego house from different angles\\n\\n6:00 - 7:00 Testing the Durability of the Lego House\\n- Fun segment where Mr. Beast and friends test the durability of the Lego house\\n- Excitement and surprises during the testing phase\\n\\n7:00 - 8:00 Conclusion and Revealing the Final Product\\n- Wrapping up the video with Mr. Beast's thoughts on the project\\n- Revealing the grand scale of the giant Lego house and showcasing it in all its glory\\n\\n8:00 - End Outro\\n- Thanking viewers for watching and encouraging them to like, share, and subscribe\\n- Teasing the next exciting project or video coming up on Mr. Beast's channel\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Testing the base model\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful chatbot that writes youtube video transcripts given a video title.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Mr.Beast is planning to make YT video with the following title: 'I Built A Giant House Using Only Legos'. what would be a good video outline?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the finetuned model creatively captures the style of the creator when generating video outlines as compared to directly prompting gpt-3.5-turbo. There are a few optimizations that can made to the model to tune it further. We made use of 50 data samples to finetune the model. Finetuning the model on a larger sample set would result in better capturing the content style of the creator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
